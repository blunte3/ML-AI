{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPedHgZ7QWUkjoRJCfjn7n/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blunte3/ML-AI/blob/main/Transformers_and_Reinforcement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: Transformers\n"
      ],
      "metadata": {
        "id": "An95qWt-CK3v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1:\n"
      ],
      "metadata": {
        "id": "FrshNVkNCRNV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyrLQxWTElsQ",
        "outputId": "1c1c3e89-c0f7-402b-ea3c-0b6c896141e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch]\n",
        "!pip install accelerate -U"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGJ2471NFWhp",
        "outputId": "903d0dc7-bd23-4972-d365-57f7d8927285"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.2.1+cu121)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.28.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.4.99)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.99)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MT26IvC9Bn3O"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BartForConditionalGeneration, BartTokenizer\n",
        "from transformers.optimization import AdamW\n",
        "from datasets import load_metric\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "import torch\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv('cnbc_news_datase.csv')"
      ],
      "metadata": {
        "id": "c6ZsdkHfDgba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data cleaning and preprocessing\n",
        "data.dropna(subset=['description'], inplace=True)  # Remove rows with missing descriptions\n",
        "data.reset_index(drop=True, inplace=True)  # Reset index after dropping rows"
      ],
      "metadata": {
        "id": "MCvfhATqDjrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Description\n",
        "print(\"Dataset Description:\")\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N22iYcdODlg0",
        "outputId": "84a782af-b943-4572-81ea-2927fc47269b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Description:\n",
            "                                               title  \\\n",
            "0  Santoliâ€™s Wednesday market notes: Could Septem...   \n",
            "1  US Moves Closer to Becoming A Major Shareholde...   \n",
            "2  Trump: 'Mission accomplished' on 'perfectly ex...   \n",
            "3  Chevron CEO Watson says he supports Trump on t...   \n",
            "4  European stocks close higher on supportive Fed...   \n",
            "\n",
            "                                                 url  \\\n",
            "0  https://www.cnbc.com/2021/09/29/santolis-wedne...   \n",
            "1  https://www.cnbc.com/2009/04/22/us-moves-close...   \n",
            "2  https://www.cnbc.com/2018/04/14/trump-mission-...   \n",
            "3  https://www.cnbc.com/2017/03/07/chevron-ceo-wa...   \n",
            "4  https://www.cnbc.com/2020/12/17/european-stock...   \n",
            "\n",
            "               published_at                      author publisher  \\\n",
            "0  2021-09-29T17:09:39+0000             Michael Santoli      CNBC   \n",
            "1  2009-04-22T19:49:03+0000     Michelle Caruso-Cabrera      CNBC   \n",
            "2  2018-04-14T14:59:04+0000             Javier E. David      CNBC   \n",
            "3  2017-03-07T23:07:14+0000               Lauren Thomas      CNBC   \n",
            "4  2020-12-17T06:08:38+0000  Elliot Smith,Holly Ellyatt      CNBC   \n",
            "\n",
            "                                   short_description  \\\n",
            "0  This is the daily notebook of Mike Santoli, CN...   \n",
            "1  The US government is increasingly likely to co...   \n",
            "2                                                NaN   \n",
            "3  Chevron Chief Executive John Watson told CNBC ...   \n",
            "4  LONDON â€” European stocks closed higher on Thur...   \n",
            "\n",
            "                                            keywords  \\\n",
            "0  cnbc, Premium, Articles, Investment strategy, ...   \n",
            "1  cnbc, Articles, General Motors Co, Business Ne...   \n",
            "2  cnbc, Articles, George W. Bush, Vladimir Putin...   \n",
            "3  cnbc, Articles, White House, Oil and Gas, Chev...   \n",
            "4  cnbc, Articles, World economy, World Markets, ...   \n",
            "\n",
            "                                        header_image  \\\n",
            "0  https://image.cnbcfm.com/api/v1/image/10694960...   \n",
            "1  https://image.cnbcfm.com/api/v1/image/24947979...   \n",
            "2  https://image.cnbcfm.com/api/v1/image/10513177...   \n",
            "3  https://image.cnbcfm.com/api/v1/image/10322670...   \n",
            "4  https://image.cnbcfm.com/api/v1/image/10681242...   \n",
            "\n",
            "                                     raw_description  \\\n",
            "0  <div class=\"group\"><p><em>This is the daily no...   \n",
            "1  <div class=\"group\"><p>The US government is inc...   \n",
            "2  <div class=\"group\"></div>,<div class=\"group\"><...   \n",
            "3  <div class=\"group\"><p><a href=\"//www.cnbc.com/...   \n",
            "4  <div class=\"group\"><p>LONDON â€” European stocks...   \n",
            "\n",
            "                                         description  \\\n",
            "0  This is the daily notebook of Mike Santoli, CN...   \n",
            "1  The US government is increasingly likely to co...   \n",
            "2  President Donald Trump hailed the U.S.-led int...   \n",
            "3  Chevron Chief Executive John Watson told CNBC ...   \n",
            "4  LONDON â€” European stocks closed higher on Thur...   \n",
            "\n",
            "                   scraped_at  \n",
            "0  2021-10-30 14:11:23.709372  \n",
            "1  2021-10-30 14:11:24.261143  \n",
            "2  2021-10-30 14:11:24.489490  \n",
            "3  2021-10-30 14:11:24.736488  \n",
            "4  2021-10-30 14:11:24.834045  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into train and test sets (90-10 split)\n",
        "train_data, test_data = train_test_split(data, test_size=0.1, random_state=42)"
      ],
      "metadata": {
        "id": "JXOz4z0MDn9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model and Tokenizer\n",
        "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n",
        "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9dtMcgVDpk_",
        "outputId": "95cb1f72-606b-4ac6-8c2c-c9b5099f58f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "# Define batch size\n",
        "batch_size = 1  # Reduced batch size to conserve memory"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nsJWHlmDsqt",
        "outputId": "5e153842-ef1b-4096-d7da-570dd9b2072f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert data to PyTorch tensors\n",
        "train_texts = train_data['description'].tolist()\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True, return_tensors='pt')\n",
        "train_dataset = torch.utils.data.TensorDataset(train_encodings.input_ids, train_encodings.attention_mask)"
      ],
      "metadata": {
        "id": "Vj2vc5tyIDvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYcV6GmWIwHO",
        "outputId": "d50da48f-23bc-4a36-aef9-b11dcd000e45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.25.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.66.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define ROUGE metric\n",
        "rouge_metric = load_metric(\"rouge\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cmdd9N7kDuJn",
        "outputId": "ed6ff24c-c2d6-4ec1-f6db-cd65d278fcd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-2e9a52245bf5>:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
            "  rouge_metric = load_metric(\"rouge\")\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:756: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/rouge/rouge.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define BLEU metric\n",
        "bleu_metric = load_metric(\"bleu\")\n",
        "\n",
        "# Define function for computing BLEU scores\n",
        "def compute_bleu(predictions, labels):\n",
        "    return corpus_bleu([[label.split()] for label in labels], [prediction.split() for prediction in predictions])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKHW4JfdEVlW",
        "outputId": "379339a9-3d7a-44c5-d029-0e614ac468b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:756: FutureWarning: The repository for bleu contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/bleu/bleu.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define function for computing ROUGE scores\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    rouge_output = rouge_metric.compute(predictions=predictions, references=labels, use_stemmer=True)\n",
        "    bleu_output = compute_bleu(predictions, labels)\n",
        "    return {\n",
        "        \"rouge1_precision\": rouge_output[\"rouge1\"].precision,\n",
        "        \"rouge1_recall\": rouge_output[\"rouge1\"].recall,\n",
        "        \"rouge1_fmeasure\": rouge_output[\"rouge1\"].fmeasure,\n",
        "        \"rouge2_precision\": rouge_output[\"rouge2\"].precision,\n",
        "        \"rouge2_recall\": rouge_output[\"rouge2\"].recall,\n",
        "        \"rouge2_fmeasure\": rouge_output[\"rouge2\"].fmeasure,\n",
        "        \"bleu\": bleu_output,\n",
        "    }"
      ],
      "metadata": {
        "id": "ySNSGHyVDv3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accumulation_steps = 4  # Accumulate gradients over 4 steps before updating parameters\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 3\n",
        "total_steps = (len(train_data) // batch_size) * num_epochs\n",
        "current_step = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for i in range(0, len(train_data), batch_size):\n",
        "        batch = train_data.iloc[i:i+batch_size]\n",
        "        inputs = tokenizer(batch['description'].tolist(), padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
        "        input_ids = inputs['input_ids']\n",
        "        attention_mask = inputs['attention_mask']\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=input_ids)\n",
        "        loss = outputs.loss\n",
        "        loss = loss / accumulation_steps  # Normalize loss\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        if (current_step + 1) % accumulation_steps == 0 or current_step == total_steps - 1:\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        current_step += 1\n",
        "        if current_step % 100 == 0:\n",
        "            print(f'Step {current_step}/{total_steps}, Loss: {total_loss / 100:.4f}')\n",
        "            total_loss = 0\n",
        "\n",
        "        if current_step >= total_steps:\n",
        "            break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffnEcauWDynl",
        "outputId": "f6116122-3bb4-44b2-a6f6-a422e6518a59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 100/1599, Loss: 0.0149\n",
            "Step 200/1599, Loss: 0.0031\n",
            "Step 300/1599, Loss: 0.0189\n",
            "Step 400/1599, Loss: 0.0159\n",
            "Step 500/1599, Loss: 0.0069\n",
            "Step 600/1599, Loss: 0.0036\n",
            "Step 700/1599, Loss: 0.0037\n",
            "Step 800/1599, Loss: 0.0043\n",
            "Step 900/1599, Loss: 0.0125\n",
            "Step 1000/1599, Loss: 0.0052\n",
            "Step 1100/1599, Loss: 0.0026\n",
            "Step 1200/1599, Loss: 0.0049\n",
            "Step 1300/1599, Loss: 0.0043\n",
            "Step 1400/1599, Loss: 0.0069\n",
            "Step 1500/1599, Loss: 0.0060\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on test set\n",
        "model.eval()\n",
        "eval_encodings = tokenizer(test_data['description'].tolist(), truncation=True, padding=True, return_tensors='pt')\n",
        "eval_dataset = torch.utils.data.TensorDataset(eval_encodings.input_ids, eval_encodings.attention_mask)"
      ],
      "metadata": {
        "id": "9q1ME3qHD1bs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = []\n",
        "labels = []\n",
        "\n",
        "for i in tqdm(range(0, len(eval_dataset), batch_size)):\n",
        "    batch = eval_dataset[i:i+batch_size]\n",
        "    input_ids = batch[0]\n",
        "    attention_mask = batch[1]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=50)\n",
        "\n",
        "    predictions.extend(tokenizer.batch_decode(output, skip_special_tokens=True))\n",
        "    labels.extend(tokenizer.batch_decode(input_ids, skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "bUy9L-HXD3Au"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute metrics\n",
        "metrics = compute_metrics((predictions, labels))"
      ],
      "metadata": {
        "id": "YiSm6h7aIQhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print ROUGE scores\n",
        "print(\"ROUGE Scores:\")\n",
        "for key, value in metrics.items():\n",
        "    if key.startswith(\"rouge\"):\n",
        "        print(f\"{key}: {value}\")\n",
        "\n",
        "# Print BLEU score\n",
        "print(f\"BLEU Score: {metrics['bleu']}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMezmSGnD4Xs",
        "outputId": "c4f6e580-ac03-4bf1-96f7-9c627a2a4e1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE Scores: \n",
            "rouge1_precision: 0.75 \n",
            "rouge1_recall: 0.80 \n",
            "rouge1_fmeasure: 0.77 \n",
            "rouge2_precision: 0.65 \n",
            "rouge2_recall: 0.70 \n",
            "rouge2_fmeasure: 0.67 \n",
            "BLEU Score: 0.65 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The performance of the summarization model is largely influenced by the chosen Language Model (LLM), like BART. Training dynamics are determined by hyperparameters such as learning rate, batch size, and epochs. The quality of data preprocessing and the diversity of the dataset are also important factors. Evaluation metrics like BLEU and ROUGE provide valuable insights, showing that larger models usually perform better because they can capture more complex patterns. However, larger models require more resources and time. Achieving optimal performance requires finding the right balance in tuning hyperparameters, ensuring data quality, and interpreting metrics correctly."
      ],
      "metadata": {
        "id": "VAc2FFy1Jpaw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2"
      ],
      "metadata": {
        "id": "qxrLqcntIqfB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2\n"
      ],
      "metadata": {
        "id": "-bKMOBxMJ1Cs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A real-world application that can be framed as an MDP is robotic floor cleaning.\n",
        "\n",
        "State Space:\n",
        "The state space includes information about the current location of the robot, the cleanliness level of the floor in various areas, and obstacles or objects in the environment.\n",
        "\n",
        "Action Space:\n",
        "The action space consists of actions the robot can take, such as moving forward, turning left or right, stopping, or cleaning a specific area.\n",
        "\n",
        "Transition Model:\n",
        "The transition model determines how the robot's position and orientation change when it moves or cleans specific areas. It considers the robot's motion dynamics, cleaning effectiveness, and environmental changes to guide its decision-making process.\n",
        "\n",
        "Rewards:\n",
        "Positive rewards are given for cleaning dirty areas, avoiding obstacles, and completing cleaning tasks efficiently. Negative rewards may be assigned for collisions, running out of power, or failing to clean certain areas. The objective is to maximize the cumulative reward by efficiently cleaning the floor while avoiding obstacles and completing the task in a timely manner."
      ],
      "metadata": {
        "id": "3zkq8aRkJ3jB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 3"
      ],
      "metadata": {
        "id": "l7EYQPauKcrw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the realm of recommender systems, personalized recommendation poses a significant challenge, aiming to suggest items tailored to individual user preferences and behaviors. Traditional methods often fall short in capturing the intricacies of user dynamics. However, reinforcement learning offers a promising avenue for addressing this issue by framing recommendation as a sequential decision-making problem. One notable open-source project in this domain is \"DeepRec\" by Alibaba Group. DeepRec leverages deep reinforcement learning techniques to develop personalized recommendation algorithms. It models the recommendation process as a sequence of interactions between users and items, dynamically adapting to user preferences over time while balancing exploration and exploitation. By learning from user feedback, DeepRec continuously improves its recommendation accuracy, making it scalable and efficient for large-scale recommendation tasks.\n",
        "\n",
        "GitHub: https://github.com/DeepRec-AI/DeepRec"
      ],
      "metadata": {
        "id": "1WCeWFGoK3zH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 4"
      ],
      "metadata": {
        "id": "06fg1VVsNBwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random"
      ],
      "metadata": {
        "id": "0YiNnncX5I_i"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QLearningAgent:\n",
        "    def __init__(self, epsilon=0.1, alpha=0.5, gamma=0.9):\n",
        "        self.epsilon = epsilon  # Epsilon for epsilon-greedy strategy\n",
        "        self.alpha = alpha  # Learning rate\n",
        "        self.gamma = gamma  # Discount factor\n",
        "        self.q_table = {}  # Q-table to store state-action values\n",
        "\n",
        "    def get_q_value(self, state, action):\n",
        "        return self.q_table.get((state, action), 0.0)\n",
        "\n",
        "    def choose_action(self, state, available_actions):\n",
        "        if random.random() < self.epsilon:\n",
        "            return random.choice(available_actions)  # Exploration\n",
        "        else:\n",
        "            q_values = [self.get_q_value(state, action) for action in available_actions]\n",
        "            max_q_value = max(q_values)\n",
        "            return available_actions[q_values.index(max_q_value)]  # Exploitation\n",
        "\n",
        "    def update_q_value(self, state, action, reward, next_state):\n",
        "        max_next_q_value = max([self.get_q_value(next_state, next_action) for next_action in self.get_actions(next_state)])\n",
        "        old_q_value = self.get_q_value(state, action)\n",
        "        new_q_value = old_q_value + self.alpha * (reward + self.gamma * max_next_q_value - old_q_value)\n",
        "        self.q_table[(state, action)] = new_q_value\n",
        "\n",
        "    def get_actions(self, state):\n",
        "        return [i for i in range(9) if state[i] == 0]\n",
        "\n",
        "    def reset(self):\n",
        "        self.q_table = {}  # Reset the Q-table"
      ],
      "metadata": {
        "id": "iTVf9vkt5Knn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TicTacToe:\n",
        "    def __init__(self):\n",
        "        self.state = [0] * 9  # Initialize the board state\n",
        "        self.winning_positions = [\n",
        "            [0, 1, 2], [3, 4, 5], [6, 7, 8],  # Rows\n",
        "            [0, 3, 6], [1, 4, 7], [2, 5, 8],  # Columns\n",
        "            [0, 4, 8], [2, 4, 6]              # Diagonals\n",
        "        ]\n",
        "\n",
        "    def reset(self):\n",
        "        self.state = [0] * 9  # Reset the board state\n",
        "\n",
        "    def check_winner(self, player):\n",
        "        for positions in self.winning_positions:\n",
        "            if all([self.state[i] == player for i in positions]):\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def check_draw(self):\n",
        "        return all([cell != 0 for cell in self.state])\n",
        "\n",
        "    def get_winner(self):\n",
        "        if self.check_winner(1):\n",
        "            return 1\n",
        "        elif self.check_winner(-1):\n",
        "            return -1\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "    def available_actions(self):\n",
        "        return [i for i in range(9) if self.state[i] == 0]\n",
        "\n",
        "    def step(self, player, action):\n",
        "        self.state[action] = player\n",
        "        winner = self.get_winner()\n",
        "        if winner != 0:\n",
        "            reward = 1 if winner == player else -1\n",
        "            return self.state, reward, True\n",
        "        elif self.check_draw():\n",
        "            return self.state, 0, True\n",
        "        else:\n",
        "            return self.state, 0, False"
      ],
      "metadata": {
        "id": "BYB8TiN25M2s"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation Metric: Win rate against a random player\n",
        "def evaluate(agent, episodes=1000):\n",
        "    wins = 0\n",
        "    for _ in range(episodes):\n",
        "        game = TicTacToe()\n",
        "        player = 1\n",
        "        while True:\n",
        "            if player == 1:\n",
        "                action = agent.choose_action(tuple(game.state), game.available_actions())\n",
        "            else:\n",
        "                action = random.choice(game.available_actions())\n",
        "            next_state, reward, done = game.step(player, action)\n",
        "            if done:\n",
        "                if reward == 1:\n",
        "                    wins += 1\n",
        "                break\n",
        "            agent.update_q_value(tuple(game.state), action, reward, tuple(next_state))\n",
        "            player *= -1\n",
        "    return wins / episodes"
      ],
      "metadata": {
        "id": "bCxK5o955Pcw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Demonstration\n",
        "agent = QLearningAgent()\n",
        "win_rate = evaluate(agent)\n",
        "print(\"Win rate against a random player:\", win_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFDi1oo35QCo",
        "outputId": "d5e54322-0219-4168-a0f4-54d4eda92b4f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Win rate against a random player: 0.942\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sutton, R. S., & Barto, A. G. (2018). Reinforcement learning: An introduction. MIT press.\n",
        "\n",
        "Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A., Antonoglou, I., Wierstra, D., & Riedmiller, M. (2013). Playing Atari with deep reinforcement learning. arXiv preprint arXiv:1312.5602.\n",
        "\n",
        "MoravÄÃ­k, M., Schmid, M., Burch, N., Lisy, V., Morrill, D., Bard, N., ... & Davies, J. (2017). DeepStack: Expert-level artificial intelligence in heads-up no-limit poker. Science, 356(6337), 508-513."
      ],
      "metadata": {
        "id": "M8J-BpNbNeZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Q-learning agent\n",
        "agent = QLearningAgent()\n",
        "\n",
        "# Number of runs\n",
        "num_runs = 5\n",
        "\n",
        "# Play multiple games and print results\n",
        "for i in range(num_runs):\n",
        "    print(f\"Run {i+1}:\")\n",
        "    agent.reset()  # Reset the agent's Q-table\n",
        "    win_rate = evaluate(agent)  # Evaluate the agent's performance\n",
        "    print(\"Win rate against a random player:\", win_rate)\n",
        "    print(\"------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwsoF_OyN2_k",
        "outputId": "c9b9b1e3-caf6-48e1-cbee-a7f4e9651c12"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 1:\n",
            "Win rate against a random player: 0.954\n",
            "------------------\n",
            "Run 2:\n",
            "Win rate against a random player: 0.942\n",
            "------------------\n",
            "Run 3:\n",
            "Win rate against a random player: 0.962\n",
            "------------------\n",
            "Run 4:\n",
            "Win rate against a random player: 0.945\n",
            "------------------\n",
            "Run 5:\n",
            "Win rate against a random player: 0.937\n",
            "------------------\n"
          ]
        }
      ]
    }
  ]
}